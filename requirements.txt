fastapi==0.104.1
uvicorn[standard]==0.24.0
python-dotenv==1.0.0
pydantic==2.5.0
azure-ai-documentintelligence==1.0.0b1
azure-search-documents==11.4.0
azure-core==1.29.5
openai==1.3.0
python-multipart==0.0.6
PyPDF2==3.0.1

# Optional: tiktoken for accurate token counting
# If installation fails (e.g., requires Rust compiler on Python 3.14+), 
# the code will automatically use token estimation instead.
# To install tiktoken manually (if you have Rust or prebuilt wheels):
# pip install tiktoken
# Otherwise, skip it - the chunking service works fine with estimation.